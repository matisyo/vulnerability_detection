import pandas as pd
import numpy as np

import sys
sys.path.append('../')

CONTRACTS_PATH = '../contracts'
BYTECODES_PATH = '../data/bytecodes'
OPCODES_PATH = '../data/opcodes'
VULNERABILITIES_PATH = '../data'
DATASETS_PATH = '../data/datasets'


opc = []
for i in range(0,44):
    desde = i*1000
    hasta = (i+1)*1000
    print(desde,hasta,end='\r')
    try:
        opc.append(pd.read_csv(f'{OPCODES_PATH}/opcode_contratos_{desde}_{hasta}.csv') )
    except:
        continue
opc.append(pd.read_csv(f'{OPCODES_PATH}/opcode_contratos_final.csv') )
opc = pd.concat(opc)

def splitear_en_body(code):
    remove_call_chunk = code.split('CALLDATASIZE')[-1].split('CALLDATALOAD')[-1]
    if 'REVERT JUMPDEST' in remove_call_chunk:
        return 'JUMPDEST'.lower()+'REVERT JUMPDEST'.join(code.split('CALLDATASIZE')[-1].split('CALLDATALOAD')[-1].split('REVERT JUMPDEST')[1:]).lower()
    return remove_call_chunk.lower()

opc['opcode_clean'] = opc.opcode.apply(lambda x:' '.join([j if 'UNKNOWN' not in j else 'UNKNOWN'  for j in x.split(',')]) )
opc['opcode_nocds'] = opc.opcode_clean.apply(splitear_en_body)

print(opc.opcode.shape,opc.opcode.drop_duplicates().shape)
print(opc[['opcode_nocds']].shape,opc[['opcode_nocds']].drop_duplicates().shape,opc[['file','opcode_nocds']].drop_duplicates().shape)

vuln = pd.read_csv(f'{VULNERABILITIES_PATH}/vulnerabilities.csv')
dataset = opc.merge(vuln,left_on='file',right_on='contrato').drop('contrato',axis=1)
dataset['n_instructions'] = dataset.opcode_nocds.apply(lambda x:len(x.split(' ')))
dataset = dataset[(dataset['n_instructions']<=4048)&(dataset['n_instructions']>=64)]

def add_validation(dataset,valic_pct = .1):
    dataset['is_valid'] = np.where(dataset.index.isin(dataset.sample(int(dataset.shape[0]*valic_pct)).index),True,False)

# Lang Model Dataset
lang_model = dataset.copy()
add_validation(lang_model,.1)
lang_model[['opcode_nocds','is_valid']].to_csv(f'{DATASETS_PATH}/lang_model_dataset.csv',index=False)

# Transformers LangModel Dataset
lang_model = dataset.copy()
lang_model[['opcode_nocds']].drop_duplicates()

# All Vulnerabilities splits
def generate_classification_dataset(dataset,col,pct=.25):
    vulnerable = dataset[(dataset[col]==1)&(dataset['size']==1)][['opcode_nocds',col]].drop_duplicates()
    sin_problemas = dataset[(dataset[col]==0)][['opcode_nocds',col]].drop_duplicates().sample(vulnerable.shape[0])

    df = pd.concat([vulnerable,sin_problemas])
    add_validation(df,pct)
    print(df.shape[0],vulnerable.shape[0],sin_problemas.shape[0])
    df[['opcode_nocds',col,'is_valid']].to_csv(f'{DATASETS_PATH}/{col}_balanced.csv',index=False)

for col in ['access_control','arithmetic', 'denial_service',
       'front_running', 'reentrancy', 'time_manipulation',
       'unchecked_low_calls']:
    print(col,dataset[(dataset[col]==1)&(dataset['size']==1)].shape)
    generate_classification_dataset(dataset,col,pct=.25)
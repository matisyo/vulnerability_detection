import torch
from transformers import RobertaModel,Trainer
from transformers.modeling_outputs import SequenceClassifierOutput
from torch import nn
from sklearn.metrics import precision_recall_fscore_support, accuracy_score,roc_auc_score,recall_score,f1_score,precision_score
import pandas as pd
import numpy as np

class SiameseRobertaModel(nn.Module):
    def __init__(self,config,pretrained='',n_childs=8): 
        super(SiameseRobertaModel,self).__init__() 
        self.num_labels = config.num_labels
        self.config = config
        self.n_childs=n_childs
        if len(pretrained)==0:
            self.roberta = RobertaModel(config, add_pooling_layer=False)
        else:
            self.roberta = RobertaModel.from_pretrained(pretrained,add_pooling_layer=False)

        self.dropout = nn.Dropout(0.1) 
        self.classifier = nn.Linear(config.hidden_size*n_childs,2) # load and initialize weights
        self.min_sentence_size = 4096//n_childs
        
    def forward(
        self,
        input_ids = None,
        attention_mask = None,
        token_type_ids = None,
        position_ids= None,
        head_mask = None,
        inputs_embeds = None,
        labels= None,
        output_attentions = None,
        output_hidden_states = None,
        return_dict = None,
    ):
        rs = [self.dropout(self.roberta(input_ids[:,i*self.min_sentence_size:(i+1)*self.min_sentence_size],attention_mask[:,i*self.min_sentence_size:(i+1)*self.min_sentence_size]).last_hidden_state)[:,0,:]  for i in range(self.n_childs)] #idem: m1()[0]
        rs = torch.concat(rs,dim=1)
        logits = self.classifier(rs) # calculate losses
        
        loss = None
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
            
        if not return_dict:
            output = (logits,) #+ outputs[2:]
            return ((loss,) + output) if loss is not None else output

        return SequenceClassifierOutput(
            loss=loss,
            logits=logits,
            hidden_states=None,#outputs.hidden_states,
            attentions=None#outputs.attentions,
        )
    
class TrainerLogger(Trainer):
    def log(self, logs):
        logs["learning_rate"] = self._get_learning_rate()
        super().log(logs)
              

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }


def get_preds(model,data):
    l = []
    n = len(data['input_ids'])
    delta = 128
    with torch.no_grad():
        model.cuda()
        for i in range(0,n,delta):
            print(i,i+delta)
            x = torch.tensor(data[i:i+delta]['input_ids']).cuda()
            x_t = torch.tensor(data[i:i+delta]['attention_mask']).cuda()
            res = model(x,x_t)[0].cpu()
            l.append(res)
        model.cpu()
    y_pred = torch.concat(l)
    y_pred = torch.softmax(y_pred,dim=1)[:,1].numpy()
    y_real = np.array(data['labels'])
    return y_real,y_pred

def update_metrics(target,resultados,data):
    resultados[target] = []

    y_train,train_pred,y_valid,valid_pred = data
    
    thresholds = np.arange(0, 1, 0.001)
    scores = [f1_score(y_train, (train_pred>= t).astype('int') ) for t in thresholds]
    ix = np.argmax(scores)
    th = thresholds[ix]

    resultados[target].append(round(f1_score(y_valid, (valid_pred>= th).astype('int') ) ,6))
    resultados[target].append(round(roc_auc_score(y_valid, (valid_pred>= th).astype('int') ) ,6))
    resultados[target].append(round(roc_auc_score(y_valid, valid_pred ) ,6))
    resultados[target].append(round(precision_score(y_valid, (valid_pred>= th).astype('int') ) ,6))
    resultados[target].append(round(recall_score(y_valid, (valid_pred>= th).astype('int') ) ,6))
    resultados[target].append(round(accuracy_score(y_valid, (valid_pred>= th).astype('int') ) ,6))
    resultados[target].append(f"{(y_valid==1).sum()}/{y_valid.shape[0]}")
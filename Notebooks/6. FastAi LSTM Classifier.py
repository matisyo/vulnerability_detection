from fastai.text.all import *
import pandas as pd
import pickle
from sklearn.metrics import roc_auc_score,recall_score,f1_score,precision_score,accuracy_score
import numpy as np


DATASETS_PATH = '../data/datasets'
TOKENIZER_PATH = f'../data/tokenizers/tokenizer_word_piece'
MODEL_PATH ='../data/models/'
MODEL_DIR='lstm_lm'
RESULTADOS_PATH = f'../data/resultados'


def update_metrics(learn, target, resultados):
    resultados[target] = []
    train_dataset = learn.get_preds(ds_idx=0, with_input=True)  # train_set
    valid_dataset = learn.get_preds(ds_idx=1, with_input=True)  # valid_set

    train_pred = train_dataset[1][:, 1].numpy()
    y_train = train_dataset[2].numpy()

    valid_pred = valid_dataset[1][:, 1].numpy()
    y_valid = valid_dataset[2].numpy()
    thresholds = np.arange(0, 1, 0.001)
    scores = [f1_score(y_train, (train_pred >= t).astype('int')) for t in thresholds]
    ix = np.argmax(scores)
    th = thresholds[ix]

    resultados[target].append(round(f1_score(y_valid, (valid_pred >= th).astype('int')), 6))
    resultados[target].append(round(roc_auc_score(y_valid, (valid_pred >= th).astype('int')), 6))
    resultados[target].append(round(roc_auc_score(y_valid, valid_pred), 6))
    resultados[target].append(round(precision_score(y_valid, (valid_pred >= th).astype('int')), 6))
    resultados[target].append(round(recall_score(y_valid, (valid_pred >= th).astype('int')), 6))
    resultados[target].append(round(accuracy_score(y_valid, (valid_pred >= th).astype('int')), 6))
    resultados[target].append(f"{(y_valid == 1).sum()}/{y_valid.shape[0]}")


def train_model(target, vocab, resultados, use_lm=True):
    # dataset = pd.read_csv('lm_dataset.csv')
    dataset = pd.read_csv(f'{DATASETS_PATH}/{target}_balanced.csv')[['opcode_nocds', target, 'is_valid']]
    dataset[target] = np.where(dataset[target] == 1, 'Danger', 'Safe')

    dblk_lm = DataBlock(
        blocks=(TextBlock.from_df('opcode_nocds', seq_len=4048, n_workers=0, vocab=vocab), CategoryBlock),
        get_x=ColReader('text'),
        get_y=ColReader(target),
        splitter=ColSplitter())

    dls = dblk_lm.dataloaders(dataset, bs=16, seq_len=4048, n_workers=0)

    learn = text_classifier_learner(dls,
                                    AWD_LSTM,
                                    seq_len=4048,
                                    max_len=4048,
                                    pretrained=False,
                                    wd=0.1,
                                    drop_mult=1,
                                    metrics=[accuracy],
                                    path=MODEL_PATH,
                                    model_dir=MODEL_DIR).to_fp16()
    if use_lm:
        learn.load_encoder('lm_encoder')
        learn.fit_one_cycle(3, 1e-3)
        learn.freeze_to(-2)
        learn.fit_one_cycle(3, 1e-4)
        learn.unfreeze()
        learn.fit_one_cycle(3, 1e-4)
    else:
        learn.fit_one_cycle(5, 1e-3)

    update_metrics(learn, target, resultados)



with open(f'{TOKENIZER_PATH}/vocabulary.pkl', 'rb') as f:
    vocab = pickle.load(f)

vulnerabilities = ['access_control', 'arithmetic', 'denial_service',
       'front_running', 'reentrancy', 'time_manipulation',
       'unchecked_low_calls']

resultados = {
    'fold':['f1','auc-roc','auc-roc-th','precision','recall','accuracy','size'],
}

for vuln in vulnerabilities:
    print(vuln)
    train_model(vuln,vocab,resultados,use_lm=True)
pd.DataFrame(resultados).to_csv(f'{RESULTADOS_PATH}/lstm_yes_lm.csv',index=False)


with open(f'{TOKENIZER_PATH}/vocabulary.pkl', 'rb') as f:
    vocab = pickle.load(f)

vulnerabilities = ['access_control', 'arithmetic', 'denial_service',
       'front_running', 'reentrancy', 'time_manipulation',
       'unchecked_low_calls']

resultados = {
    'fold':['f1','auc-roc','auc-roc-th','precision','recall','accuracy','size'],
}

for vuln in vulnerabilities:
    print(vuln)
    train_model(vuln,vocab,resultados,use_lm=False)
pd.DataFrame(resultados).to_csv(f'{RESULTADOS_PATH}/lstm_no_lm.csv',index=False)

from fastai.text.all import *
import pandas as pd


LANG_MODEL_DATASET = f'../data/datasets/lang_model_dataset.csv'
TOKENIZER_PATH = f'../data/tokenizers/tokenizer_word_piece'
MODEL_PATH ='../data/models/'
MODEL_DIR='lstm_lm'

dataset = pd.read_csv(LANG_MODEL_DATASET)
print(dataset.shape)

dblk_lm = DataBlock(blocks=TextBlock.from_df('opcode_nocds', is_lm=True,seq_len=4048,n_workers=0),
                    get_x=ColReader('text'),
                    splitter=ColSplitter())

dls_lm = dblk_lm.dataloaders(dataset, bs=16, seq_len=4048,n_workers=0)
dls_lm.show_batch(max_n=2)


learn = language_model_learner(dls_lm,
                               AWD_LSTM,
                               metrics=[accuracy, Perplexity()],
                               wd=0.1,
                               pretrained=False,
                               path=MODEL_PATH,
                               model_dir=MODEL_DIR).to_fp16()

learn.unfreeze()
learn.fit_one_cycle(6, 1e-3)
learn.save_encoder(f'lm_encoder')
learn.save(f'complete_lm')

import pickle
with open(f'{TOKENIZER_PATH}/vocabulary.pkl', 'wb') as f:
    pickle.dump(dls_lm.vocab, f)